{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>ans1809.txt</td>\n",
       "      <td>Your description may correspond to Neuralgia; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>ans1758.txt</td>\n",
       "      <td>You are most probably experiencing a musculo-s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>a7369.txt</td>\n",
       "      <td>Restrain yourself to eat during the hours that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>a31604.txt</td>\n",
       "      <td>Hi I wouldnt do it cause if you start you migh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>a55.txt</td>\n",
       "      <td>Fool proof way.\\n\\nFill a glass of water.\\nLea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>a116.txt</td>\n",
       "      <td>Ashtanga is great, like the above answer says....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>a61443.txt</td>\n",
       "      <td>Not a lot.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>ans1428.txt</td>\n",
       "      <td>The overall effects of cetrizine and iterax (h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>ans128.txt</td>\n",
       "      <td>Because you missed 3 birth control pills in we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>a69660.txt</td>\n",
       "      <td>I have the same problem. When school comes aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>ans1696.txt</td>\n",
       "      <td>Vertigo may be caused due to a lot of conditio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>ans926.txt</td>\n",
       "      <td>Neosporin in a topical antibacterial medicatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>a7453.txt</td>\n",
       "      <td>Either your throat is a little swollen, or muc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>a61392.txt</td>\n",
       "      <td>It hurts alot!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>ans820.txt</td>\n",
       "      <td>Lactose intolerance develops because of the in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>a69468.txt</td>\n",
       "      <td>Do you *really* think you can cheat on your gi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>a7334.txt</td>\n",
       "      <td>EMS stands for a lot of things. Go here:\\n\\nht...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>ans1621.txt</td>\n",
       "      <td>Though the chances of pregnancy are minimal, I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                                               text  class\n",
       "848   ans1809.txt  Your description may correspond to Neuralgia; ...      1\n",
       "697   ans1758.txt  You are most probably experiencing a musculo-s...      1\n",
       "1468    a7369.txt  Restrain yourself to eat during the hours that...      0\n",
       "1155   a31604.txt  Hi I wouldnt do it cause if you start you migh...      0\n",
       "234       a55.txt  Fool proof way.\\n\\nFill a glass of water.\\nLea...      0\n",
       "1451     a116.txt  Ashtanga is great, like the above answer says....      0\n",
       "1730   a61443.txt                                        Not a lot.       0\n",
       "471   ans1428.txt  The overall effects of cetrizine and iterax (h...      1\n",
       "542    ans128.txt  Because you missed 3 birth control pills in we...      1\n",
       "520    a69660.txt  I have the same problem. When school comes aro...      0\n",
       "1473  ans1696.txt  Vertigo may be caused due to a lot of conditio...      1\n",
       "706    ans926.txt  Neosporin in a topical antibacterial medicatio...      1\n",
       "850     a7453.txt  Either your throat is a little swollen, or muc...      0\n",
       "1130   a61392.txt                                    It hurts alot!       0\n",
       "121    ans820.txt  Lactose intolerance develops because of the in...      1\n",
       "837    a69468.txt  Do you *really* think you can cheat on your gi...      0\n",
       "896     a7334.txt  EMS stands for a lot of things. Go here:\\n\\nht...      0\n",
       "1106  ans1621.txt  Though the chances of pregnancy are minimal, I...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a pandas dataframe\n",
    "import pandas as pd\n",
    "import os\n",
    "def data2df (path, label):\n",
    "    file, text = [], []\n",
    "    for f in os.listdir(path):\n",
    "        file.append(f)\n",
    "        fhr = open(path+f, 'r',encoding=\"utf8\", errors='ignore') \n",
    "        t = fhr.read()\n",
    "        text.append(t)\n",
    "        fhr.close()\n",
    "    return(pd.DataFrame({'file': file, 'text': text, 'class':label}))\n",
    "\n",
    "NonPro = data2df('Data/HealthProNonPro/NonPro/', 0) # NonPro\n",
    "Pro = data2df('Data/HealthProNonPro/Pro/', 1) # Pro\n",
    "\n",
    "df = pd.concat([NonPro, Pro], axis=0)\n",
    "df.sample(frac=0.005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:  Set up data and split data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['text']\n",
    "y=df['class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a custom preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Create Preprocess function\n",
    "\n",
    "def preprocess(text):\n",
    "    # replace one or more white-space characters with a space\n",
    "    regex = re.compile(r\"\\s+\")                               \n",
    "    text = regex.sub(' ', text)    \n",
    "    # lower case\n",
    "    text = text.lower()          \n",
    "    # remove digits and punctuation\n",
    "    regex = re.compile(r\"[%s%s]\" % (string.punctuation, string.digits))\n",
    "    text = regex.sub(' ', text)           \n",
    "    # remove stop words\n",
    "    sw = stopwords.words('english')\n",
    "    text = text.split()                                              \n",
    "    text = ' '.join([w for w in text if w not in sw]) \n",
    "    # remove short words\n",
    "    ' '.join([w for w in text.split() if len(w) >= 4])\n",
    "    # lemmatize\n",
    "    text = ' '.join([(WordNetLemmatizer()).lemmatize(w) for w in text.split()]) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Pipeline with preprocess and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step up Pipeline\n",
    "classifier = Pipeline(steps=[\n",
    "    ('pp', TfidfVectorizer(\n",
    "        preprocessor=preprocess,\n",
    "        use_idf=True, smooth_idf=True, norm='l2',\n",
    "        min_df=1, max_df=1.0, max_features=None, \n",
    "        ngram_range=(1, 1))),\n",
    "    ('NaiveBayes', MultinomialNB())])  #Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fit best parameter with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pp', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function preproc...True, vocabulary=None)), ('NaiveBayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'pp__norm': ['l1', 'l2', None], 'NaiveBayes__alpha': [0.01, 0.1, 0.2, 0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'pp__norm':['l1','l2',None],\n",
    "    'NaiveBayes__alpha':[0.01,0.1,0.2,0.5,1]\n",
    "}\n",
    "gscv = GridSearchCV(classifier, param_grid, iid=False, cv=5, return_train_score=False)\n",
    "gscv.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('pp', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2',\n",
      "        preprocessor=<function preproc...True, vocabulary=None)), ('NaiveBayes', MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))]) \n",
      "\n",
      "0.9434049732490273 \n",
      "\n",
      "{'NaiveBayes__alpha': 0.2, 'pp__norm': 'l2'} \n",
      "\n",
      "{'mean_fit_time': array([1.6609736 , 1.20189147, 1.22921376, 1.33773479, 1.23872137,\n",
      "       1.29899669, 1.17581186, 1.17546954, 1.17001977, 1.17027044,\n",
      "       1.23830199, 1.30429502, 1.16846867, 1.1676506 , 1.17528872]), 'std_fit_time': array([0.92369759, 0.05437371, 0.06230801, 0.10516984, 0.02459072,\n",
      "       0.12923569, 0.00541774, 0.00886681, 0.00335653, 0.00600648,\n",
      "       0.07924392, 0.10250802, 0.00642457, 0.00406087, 0.00852419]), 'mean_score_time': array([0.32524099, 0.3063952 , 0.31891823, 0.31802735, 0.34137664,\n",
      "       0.32306399, 0.29260478, 0.29086285, 0.29101167, 0.29151335,\n",
      "       0.30498791, 0.31243463, 0.29031081, 0.29139605, 0.29230804]), 'std_score_time': array([0.04141114, 0.02757562, 0.04514895, 0.01959444, 0.05393547,\n",
      "       0.03043264, 0.00376503, 0.00340195, 0.00328956, 0.0037004 ,\n",
      "       0.02543392, 0.02197247, 0.00404973, 0.0032565 , 0.00494539]), 'param_NaiveBayes__alpha': masked_array(data=[0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.5,\n",
      "                   0.5, 0.5, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_pp__norm': masked_array(data=['l1', 'l2', None, 'l1', 'l2', None, 'l1', 'l2', None,\n",
      "                   'l1', 'l2', None, 'l1', 'l2', None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'NaiveBayes__alpha': 0.01, 'pp__norm': 'l1'}, {'NaiveBayes__alpha': 0.01, 'pp__norm': 'l2'}, {'NaiveBayes__alpha': 0.01, 'pp__norm': None}, {'NaiveBayes__alpha': 0.1, 'pp__norm': 'l1'}, {'NaiveBayes__alpha': 0.1, 'pp__norm': 'l2'}, {'NaiveBayes__alpha': 0.1, 'pp__norm': None}, {'NaiveBayes__alpha': 0.2, 'pp__norm': 'l1'}, {'NaiveBayes__alpha': 0.2, 'pp__norm': 'l2'}, {'NaiveBayes__alpha': 0.2, 'pp__norm': None}, {'NaiveBayes__alpha': 0.5, 'pp__norm': 'l1'}, {'NaiveBayes__alpha': 0.5, 'pp__norm': 'l2'}, {'NaiveBayes__alpha': 0.5, 'pp__norm': None}, {'NaiveBayes__alpha': 1, 'pp__norm': 'l1'}, {'NaiveBayes__alpha': 1, 'pp__norm': 'l2'}, {'NaiveBayes__alpha': 1, 'pp__norm': None}], 'split0_test_score': array([0.92996109, 0.93190661, 0.91245136, 0.93579767, 0.94357977,\n",
      "       0.92023346, 0.93190661, 0.94163424, 0.92412451, 0.92607004,\n",
      "       0.94163424, 0.92996109, 0.90856031, 0.93190661, 0.93385214]), 'split1_test_score': array([0.9453125 , 0.94921875, 0.9453125 , 0.94140625, 0.95703125,\n",
      "       0.9453125 , 0.9375    , 0.95507812, 0.94726562, 0.93164062,\n",
      "       0.9453125 , 0.953125  , 0.91992188, 0.93945312, 0.95507812]), 'split2_test_score': array([0.9375    , 0.95117188, 0.93945312, 0.9375    , 0.95117188,\n",
      "       0.94726562, 0.93359375, 0.953125  , 0.94726562, 0.92773438,\n",
      "       0.94140625, 0.94921875, 0.91210938, 0.93164062, 0.94921875]), 'split3_test_score': array([0.91601562, 0.92578125, 0.90820312, 0.91210938, 0.92773438,\n",
      "       0.91796875, 0.9140625 , 0.92773438, 0.921875  , 0.90625   ,\n",
      "       0.92382812, 0.92773438, 0.88867188, 0.9140625 , 0.92578125]), 'split4_test_score': array([0.93164062, 0.93554688, 0.92578125, 0.93554688, 0.9375    ,\n",
      "       0.92773438, 0.9296875 , 0.93945312, 0.93359375, 0.92773438,\n",
      "       0.9375    , 0.93554688, 0.9140625 , 0.93359375, 0.9375    ]), 'mean_test_score': array([0.93208597, 0.93872507, 0.92624027, 0.93247203, 0.94340345,\n",
      "       0.93170294, 0.92935007, 0.94340497, 0.9348249 , 0.92388588,\n",
      "       0.93793622, 0.93911722, 0.90866519, 0.93013132, 0.94028605]), 'std_test_score': array([0.00966667, 0.00989116, 0.01451904, 0.01039474, 0.01026126,\n",
      "       0.01235592, 0.00805965, 0.00995049, 0.01089272, 0.00900614,\n",
      "       0.00747469, 0.01024119, 0.01065317, 0.00851494, 0.01056546]), 'rank_test_score': array([ 9,  5, 13,  8,  2, 10, 12,  1,  7, 14,  6,  4, 15, 11,  3],\n",
      "      dtype=int32)} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# search for best parameters/estimator\n",
    "\n",
    "print(gscv.best_estimator_, \"\\n\")\n",
    "#print(gscv.best_score_, \"\\n\")\n",
    "#print(gscv.best_params_, \"\\n\")\n",
    "#print(gscv.cv_results_, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.955\n",
      "Confusion matrix:\n",
      "[[502  49]\n",
      " [  1 547]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       551\n",
      "           1       0.92      1.00      0.96       548\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1099\n",
      "   macro avg       0.96      0.95      0.95      1099\n",
      "weighted avg       0.96      0.95      0.95      1099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate best_estimator_ on test data\n",
    "ypred = gscv.best_estimator_.predict(Xtest)\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy score:\",round(metrics.accuracy_score(ytest, ypred),3))\n",
    "print (\"Confusion matrix:\")\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print( )\n",
    "print(\"Classification Report:\")\n",
    "print (metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
