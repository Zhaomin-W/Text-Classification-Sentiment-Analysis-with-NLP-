{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### manipulating text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pirates of The Caribbean is quite simply Hollywood's best pirate \\nfilm in ages; a funny, rollicking swashbuckler that pays homage to the great \\nfilms of the 1930's and 1940's featuring the likes of Errol Flynn, Charles \\nLaughton, among others.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text\n",
    "text = \"\"\"Pirates of The Caribbean is quite simply Hollywood's best pirate \n",
    "film in ages; a funny, rollicking swashbuckler that pays homage to the great \n",
    "films of the 1930's and 1940's featuring the likes of Errol Flynn, Charles \n",
    "Laughton, among others.\"\"\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pirates caribbean quite simply hollywood best pirate film ages funny rollicking swashbuckler pays homage great films featuring likes errol flynn charles laughton among others'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower case\n",
    "text= text.lower()\n",
    "# remove digits  % punctuation\n",
    "import re\n",
    "import string\n",
    "pattern1=string.digits\n",
    "pattern2=string.punctuation\n",
    "regex=re.compile(r\"[%s%s]\" % (pattern1,pattern2))\n",
    "text=regex.sub(' ',text)\n",
    "# replace one or more white-space characters with a space\n",
    "\n",
    "regex=re.compile(r\"\\s+\")\n",
    "text=regex.sub(' ', text)\n",
    "# remove stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "sw=stopwords.words('english')\n",
    "text=' '.join([w for w in text.split() if w not in sw])\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pirates caribbean quite simply hollywood pirate funny rollicking swashbuckler homage great films featuring likes errol flynn charles laughton among others'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove short words\n",
    "text=' '.join([w for w in text.split() if len(w)>4])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rollicking pirate flynn homage caribbean errol quite hollywood pirates others films funny swashbuckler among likes charles laughton great featuring simply'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only unique words\n",
    "text=' '.join(set(text.split()))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rollick pirat flynn homag caribbean errol quit hollywood pirat other film funni swashbuckl among like charl laughton great featur simpli'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming （word root）\n",
    "# https://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "' '.join([(PorterStemmer()).stem(w) for w in text.split()]) \n",
    "\n",
    "#ps = PorterStemmer()\n",
    "#ps.stem(\"wolves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pirate caribbean quite simply hollywood best pirate film age funny rollicking swashbuckler pay homage great film featuring like errol flynn charles laughton among others'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization attempts to get the word root through vocabulary and morphological analysis\n",
    "# https://www.nltk.org/api/nltk.stem.html#module-nltk.stem.wordnet\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "' '.join([(WordNetLemmatizer()).lemmatize(w) for w in text.split()]) \n",
    "# lem = WordNetLemmatizer()\n",
    "# lem.lemmatize(\"wolves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"This is a brown house. This house is big. The street number is 1.\",\n",
    "          \"This is a small house. This house has 1 bedroom. The street number is 12.\",\n",
    "          \"This dog is brown. This dog likes to play.\",\n",
    "          \"The dog is in the bedroom.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brown': 3, 'house': 5, 'big': 2, 'street': 10, 'number': 7, 'small': 9, 'bedroom': 1, '12': 0, 'dog': 4, 'likes': 6, 'play': 8}\n",
      "set()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>big</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>house</th>\n",
       "      <th>likes</th>\n",
       "      <th>number</th>\n",
       "      <th>play</th>\n",
       "      <th>small</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   12  bedroom  big  brown  dog  house  likes  number  play  small  street\n",
       "0   0        0    1      1    0      2      0       1     0      0       1\n",
       "1   1        1    0      0    0      2      0       1     0      1       1\n",
       "2   0        0    0      1    2      0      1       0     1      0       0\n",
       "3   0        1    0      0    1      0      0       0     0      0       0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Occurrence \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(lowercase=True, stop_words='english',\n",
    "                   min_df=1, max_df=1.0,max_features=None,ngram_range=(1,1))\n",
    "\n",
    "# max_df (default 1.0): When building the vocabulary ignore terms that have a document frequency \n",
    "# strictly higher than the given threshold (corpus-specific stop words). \n",
    "# (min: lower than the given threshold.)\n",
    "\n",
    "df=pd.DataFrame(cv.fit_transform(corpus).toarray(),columns=cv.get_feature_names())\n",
    "print(cv.vocabulary_)\n",
    "print(cv.stop_words_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Word Occurrence (TF-IDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>big</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>house</th>\n",
       "      <th>likes</th>\n",
       "      <th>number</th>\n",
       "      <th>play</th>\n",
       "      <th>small</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         12   bedroom       big     brown       dog     house     likes  \\\n",
       "0  0.000000  0.000000  0.353553  0.353553  0.000000  0.707107  0.000000   \n",
       "1  0.333333  0.333333  0.000000  0.000000  0.000000  0.666667  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.377964  0.755929  0.000000  0.377964   \n",
       "3  0.000000  0.707107  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "\n",
       "     number      play     small    street  \n",
       "0  0.353553  0.000000  0.000000  0.353553  \n",
       "1  0.333333  0.000000  0.333333  0.333333  \n",
       "2  0.000000  0.377964  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv=TfidfVectorizer(use_idf=False, norm='l2',lowercase=True,stop_words='english',\n",
    "                 min_df=1, max_df=1.0, max_features=None,ngram_range=(1,1))\n",
    "\n",
    "df=pd.DataFrame(tv.fit_transform(corpus).toarray(),columns=tv.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>big</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>house</th>\n",
       "      <th>likes</th>\n",
       "      <th>number</th>\n",
       "      <th>play</th>\n",
       "      <th>small</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432291</td>\n",
       "      <td>0.340823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.396802</td>\n",
       "      <td>0.312843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396802</td>\n",
       "      <td>0.312843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348842</td>\n",
       "      <td>0.697684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         12   bedroom       big     brown       dog     house     likes  \\\n",
       "0  0.000000  0.000000  0.432291  0.340823  0.000000  0.681647  0.000000   \n",
       "1  0.396802  0.312843  0.000000  0.000000  0.000000  0.625687  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.348842  0.697684  0.000000  0.442462   \n",
       "3  0.000000  0.707107  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "\n",
       "     number      play     small    street  \n",
       "0  0.340823  0.000000  0.000000  0.340823  \n",
       "1  0.312843  0.000000  0.396802  0.312843  \n",
       "2  0.000000  0.442462  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tf-Idf with smooth (1+N(t))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(\n",
    "    use_idf=True, smooth_idf=True, norm='l2',\n",
    "    lowercase=True, \n",
    "    stop_words='english', \n",
    "    min_df=1, max_df=1.0, max_features=None, \n",
    "    ngram_range=(1, 1))\n",
    "df = pd.DataFrame(tv.fit_transform(corpus).toarray(), columns=tv.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc corpus \n",
    "\n",
    "document1 = \"\"\"In Greek mythology, Python (Greek: Πύθων, gen.: Πύθωνος) was the earth-dragon of \n",
    "Delphi, always represented in Greek sculpture and vase-paintings as a serpent. He presided at the \n",
    "Delphic oracle, which existed in the cult center for his mother, Gaia, \"Earth,\" Pytho being the \n",
    "place name that was substituted for the earlier Krisa.[1] Hellenes considered the site to be the \n",
    "center of the earth, represented by a stone, the omphalos or navel, which Python guarded.\"\"\"\n",
    "\n",
    "document2 = \"\"\"Monty Python (sometimes known as The Pythons)[2][3] were a British surreal comedy \n",
    "group who created the sketch comedy show Monty Python's Flying Circus, that first aired on the BBC on \n",
    "October 5, 1969. Forty-five episodes were made over four series. The Python phenomenon developed from \n",
    "the television series into something larger in scope and impact, spawning touring stage shows, films, \n",
    "numerous albums, several books, and a stage musical. The group's influence on comedy has been compared \n",
    "to The Beatles' influence on music.\"\"\"\n",
    "\n",
    "document3 = \"\"\"Python is a widely used general-purpose, high-level programming language.[19][20] \n",
    "Its design philosophy emphasizes code readability, and its syntax allows programmers to express \n",
    "concepts in fewer lines of code than would be possible in languages such as C++ or Java.[21][22] \n",
    "The language provides constructs intended to enable clear programs on both a small and large scale.\"\"\"\n",
    "\n",
    "corpus = [document1, document2, document3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19</th>\n",
       "      <th>1969</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>aired</th>\n",
       "      <th>albums</th>\n",
       "      <th>allows</th>\n",
       "      <th>bbc</th>\n",
       "      <th>beatles</th>\n",
       "      <th>...</th>\n",
       "      <th>substituted</th>\n",
       "      <th>surreal</th>\n",
       "      <th>syntax</th>\n",
       "      <th>television</th>\n",
       "      <th>touring</th>\n",
       "      <th>used</th>\n",
       "      <th>vase</th>\n",
       "      <th>widely</th>\n",
       "      <th>πύθων</th>\n",
       "      <th>πύθωνος</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133161</td>\n",
       "      <td>0.133161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         19      1969        20        21        22     aired    albums  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.126858  0.000000  0.000000  0.000000  0.126858  0.126858   \n",
       "2  0.153667  0.000000  0.153667  0.153667  0.153667  0.000000  0.000000   \n",
       "\n",
       "     allows       bbc   beatles    ...     substituted   surreal    syntax  \\\n",
       "0  0.000000  0.000000  0.000000    ...        0.133161  0.000000  0.000000   \n",
       "1  0.000000  0.126858  0.126858    ...        0.000000  0.126858  0.000000   \n",
       "2  0.153667  0.000000  0.000000    ...        0.000000  0.000000  0.153667   \n",
       "\n",
       "   television   touring      used      vase    widely     πύθων   πύθωνος  \n",
       "0    0.000000  0.000000  0.000000  0.133161  0.000000  0.133161  0.133161  \n",
       "1    0.126858  0.126858  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2    0.000000  0.000000  0.153667  0.000000  0.153667  0.000000  0.000000  \n",
       "\n",
       "[3 rows x 106 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(\n",
    "    use_idf=True, smooth_idf=True, norm='l2',\n",
    "    lowercase=True, \n",
    "    stop_words='english', \n",
    "    min_df=1, max_df=1.0, max_features=None, \n",
    "    ngram_range=(1, 1))\n",
    "df = pd.DataFrame(tv.fit_transform(corpus).toarray(), columns=tv.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "document 0:\n",
      "greek          0.399484\n",
      "earth          0.399484\n",
      "represented    0.266323\n",
      "center         0.266323\n",
      "python         0.157295\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "document 1:\n",
      "comedy       0.380573\n",
      "group        0.253715\n",
      "stage        0.253715\n",
      "series       0.253715\n",
      "influence    0.253715\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "document 2:\n",
      "language       0.307333\n",
      "code           0.307333\n",
      "general        0.153667\n",
      "programming    0.153667\n",
      "programmers    0.153667\n",
      "Name: 2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"\\ndocument 0:\")\n",
    "print (df.loc[0].sort_values(ascending=False)[:5])\n",
    "\n",
    "print (\"\\ndocument 1:\")\n",
    "print (df.loc[1].sort_values(ascending=False)[:5])\n",
    "\n",
    "print (\"\\ndocument 2:\")\n",
    "print (df.loc[2].sort_values(ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest 5 terms should be unique identifier of each documents with high TF-IDF scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>cv712_24217.txt</td>\n",
       "      <td>preposterous religious action film ( produced ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>cv860_15520.txt</td>\n",
       "      <td>i guess that if a very wild bachelor party had...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>cv621_15984.txt</td>\n",
       "      <td>synopsis : sullen julie james , still haunted ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>cv723_8648.txt</td>\n",
       "      <td>director jan de bont certainly knows how to ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv155_7845.txt</td>\n",
       "      <td>\" gordy \" is not a movie , it is a 90-minute-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>cv914_2856.txt</td>\n",
       "      <td>woof ! too bad that leap of faith was the titl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>cv057_7962.txt</td>\n",
       "      <td>supposedly based on a true story in which the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>cv021_15838.txt</td>\n",
       "      <td>one can not observe a star trek movie and expe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>cv038_9749.txt</td>\n",
       "      <td>sometimes a movie comes along that falls somew...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>cv644_18551.txt</td>\n",
       "      <td>plot : two sister witches have to live with a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                file                                               text  class\n",
       "593  cv712_24217.txt  preposterous religious action film ( produced ...      0\n",
       "379  cv860_15520.txt  i guess that if a very wild bachelor party had...      0\n",
       "936  cv621_15984.txt  synopsis : sullen julie james , still haunted ...      0\n",
       "402   cv723_8648.txt  director jan de bont certainly knows how to ma...      1\n",
       "2     cv155_7845.txt   \" gordy \" is not a movie , it is a 90-minute-...      0\n",
       "380   cv914_2856.txt  woof ! too bad that leap of faith was the titl...      0\n",
       "638   cv057_7962.txt  supposedly based on a true story in which the ...      0\n",
       "501  cv021_15838.txt  one can not observe a star trek movie and expe...      1\n",
       "581   cv038_9749.txt  sometimes a movie comes along that falls somew...      1\n",
       "686  cv644_18551.txt  plot : two sister witches have to live with a ...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a pandas dataframe\n",
    "import pandas as pd\n",
    "import os\n",
    "def data2df (path, label):\n",
    "    file, text = [], []\n",
    "    for f in os.listdir(path):\n",
    "        file.append(f)\n",
    "        fhr = open(path+f, 'r') \n",
    "        t = fhr.read()\n",
    "        text.append(t)\n",
    "        fhr.close()\n",
    "    return(pd.DataFrame({'file': file, 'text': text, 'class':label}))\n",
    "\n",
    "dfneg = data2df('Data/MoviePosNeg/neg/', 0) # NEG\n",
    "dfpos = data2df('Data/MoviePosNeg/pos/', 1) # POS\n",
    "\n",
    "df = pd.concat([dfpos, dfneg], axis=0)\n",
    "df.sample(frac=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:  Set up data and split data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data\n",
    "X, y = df['text'], df['class']\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Setup Preprocessing and Tfidf Vectorization</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def preprocess(text):\n",
    "    # replace one or more white-space characters with a space\n",
    "    regex = re.compile(r\"\\s+\")                               \n",
    "    text = regex.sub(' ', text)    \n",
    "    # lower case\n",
    "    text = text.lower()          \n",
    "    # remove digits and punctuation\n",
    "    regex = re.compile(r\"[%s%s]\" % (string.punctuation, string.digits))\n",
    "    text = regex.sub(' ', text)           \n",
    "    # remove stop words\n",
    "    sw = stopwords.words('english')\n",
    "    text = text.split()                                              \n",
    "    text = ' '.join([w for w in text if w not in sw]) \n",
    "    # remove short words\n",
    "    ' '.join([w for w in text.split() if len(w) >= 2])\n",
    "    # lemmatize\n",
    "    text = ' '.join([(WordNetLemmatizer()).lemmatize(w) for w in text.split()]) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tv = TfidfVectorizer(\n",
    "#     preprocessor=preprocess,\n",
    "#     #lowercase=True, stop_words='english', \n",
    "#     use_idf=True, smooth_idf=True, norm='l2',\n",
    "#     min_df=1, max_df=1.0, max_features=None, \n",
    "\n",
    "#     ngram_range=(1, 1))\n",
    "# XTtrain = pd.DataFrame(tv.fit_transform(Xtrain).toarray(), columns=tv.get_feature_names())\n",
    "# XTtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Pipeline with preprocess and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the preprocessing->model pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf = Pipeline(steps=[\n",
    "    ('pp', TfidfVectorizer(\n",
    "        #preprocessor=preprocess, (now is using default preprocessor)\n",
    "        lowercase=True, stop_words='english', \n",
    "        use_idf=True, smooth_idf=True, norm='l2',\n",
    "        min_df=1, max_df=1.0, max_features=None, \n",
    "        ngram_range=(1, 1))),\n",
    "    ('mdl',     MultinomialNB())  #Naive Bayes Classifier\n",
    "    #('mdl',     RandomForestClassifier())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fit best parameter with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'mdl__alpha':[0.01, 0.1, 0.2, 0.5, 1]\n",
    "    #'mdl__n_estimators':[500, 700, 1000]\n",
    "}\n",
    "gscv = GridSearchCV(clf, param_grid, iid=False, cv=4, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mdl__alpha': 1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# search for best parameters/estimator\n",
    "gscv.fit(Xtrain, ytrain)\n",
    "\n",
    "#print(gscv.best_estimator_, \"\\n\")\n",
    "#print(gscv.best_score_, \"\\n\")\n",
    "print(gscv.best_params_, \"\\n\")\n",
    "#print(gscv.cv_results_, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835\n",
      "[[173  32]\n",
      " [ 34 161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       205\n",
      "           1       0.83      0.83      0.83       195\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       400\n",
      "   macro avg       0.83      0.83      0.83       400\n",
      "weighted avg       0.83      0.83      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate best_estimator_ on test data\n",
    "ypred = gscv.best_estimator_.predict(Xtest)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred))\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print (metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
